import numpy as np

from tensorflow.keras import models

from src.WGA.interpretation import word_level_interpretation, unify_dim


# Tested
def get_layer_output(input_model, input_x, layer_name):
    """
    Get the layer output
    """
    # Get the layer from the input_model
    layer_ = input_model.get_layer(layer_name).output

    # Build temp temp_model to get the output
    temp_model = models.Model(inputs=input_model.input, outputs=layer_)

    # Get the output scores
    output = temp_model.predict(input_x)

    return output


# Tested
def get_interpretation(input_model, input_x, target_layer_name, window_size_len):
    """
    get the interpretation from the attention layer
    """
    # Get the attention scores
    attention_score = get_layer_output(input_model, input_x, layer_name='activation')

    # Get the score for each window_size of the convolution layer
    conv_output_list = list()
    for layer_idx, target_layer in enumerate(target_layer_name):

        # Get the attention scores for that convolutional window size
        start = layer_idx * window_size_len
        end = (layer_idx + 1) * window_size_len
        conv_attention = attention_score[:, start:end]

        # Get convolutional output scores and swap the filters dim
        conv_output = get_layer_output(input_model, input_x, layer_name=target_layer)
        conv_output = np.swapaxes(conv_output, 1, 2)

        # Get the maximum score of each filter
        conv_output_max = np.argmax(conv_output, axis=2)

        # Keep only the max_value of each filter (as 1) and zero out the rest
        temp = np.zeros_like(conv_output)
        for doc_idx in range(temp.shape[0]):
            for filter_idx in range(temp.shape[1]):
                max_cell_idx = conv_output_max[doc_idx, filter_idx]
                # Assign the attention score to the max_value of each filter
                temp[doc_idx, filter_idx, max_cell_idx] = conv_attention[doc_idx, filter_idx]

        # Average across the number of filters
        conv_heatmap = np.sum(temp, axis=1)

        # conv_output.append(conv_output)
        print(f'Get the scores of convolutional layer: {target_layer}')

        conv_output_list.append(conv_heatmap)

    return conv_output_list


# Tested
def attention_interpretation(input_model, input_x, window_size, target_layer_name, l_data):
    """
    Get the heatmap generated by interpretation method for each word per input text
    """
    predicted_features = []

    # Split the attention layer into len(window_size) parts
    attention_layer_dim = input_model.get_layer('activation').output.shape[-1]
    window_size_len = attention_layer_dim // len(window_size)
    print(f'The attention layer of size {attention_layer_dim} has been split into {len(window_size)} parts each of size {window_size_len}!')

    # Generate heatmap from the attention score
    heatmap = get_interpretation(input_model, input_x, target_layer_name, window_size_len)

    for idx, w_size in enumerate(window_size):

        # Distribute the heatmap to the word_level
        word_level_heatmap = word_level_interpretation(heatmap[idx], w_size)
        word_level_heatmap = unify_dim(word_level_heatmap, w_size)
        predicted_features.append(word_level_heatmap)

    attention_score = np.sum(predicted_features, axis=0) / len(window_size)

    # Processes
    output = list()
    for sample_idx in range(len(l_data)):
        sample_heatmap = attention_score[sample_idx][:l_data[sample_idx]]
        sample_heatmap = sample_heatmap - np.mean(sample_heatmap)
        sample_heatmap = np.maximum(sample_heatmap, 0)
        max_value = np.max(sample_heatmap) if np.max(sample_heatmap) > 0 else 0.000001  # Replace the zero value by 0.000001
        new_cams = sample_heatmap / max_value
        output.append(new_cams)

    return output


# Tested
def attention_interpretation_h(input_model, input_x, l_data):
    """
    Get the heatmap generated by interpretation method for each word per input text
    """
    # Generate heatmap from the attention score
    # Get the attention scores
    attention_score = get_layer_output(input_model, input_x, layer_name='scores')

    # Processes
    output = list()
    for sample_idx in range(len(l_data)):
        sample_heatmap = attention_score[sample_idx][:l_data[sample_idx]]
        sample_heatmap = sample_heatmap - np.mean(sample_heatmap)
        sample_heatmap = np.maximum(sample_heatmap, 0)
        max_value = np.max(sample_heatmap) if np.max(sample_heatmap) > 0 else 0.000001  # Replace the zero value by 0.000001
        new_cams = sample_heatmap / max_value
        output.append(new_cams)

    return output
